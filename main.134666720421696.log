[1731156677] Log start
[1731156677] Cmd: /home/ubuntu/ai_program/lama/llama.cpp/./main -m /home/ubuntu/ai_program/lama/llama.cpp/models/7B/llama-2-7b-chat.Q3_K_M.gguf --threads 8 -c 2048 -ins --in-prefix "" "" --color
[1731156677] main: build = 1232 (feea179)
[1731156677] main: seed  = 1731156677
[1731156677] main: llama backend init
[1731156677] main: load the model and apply lora adapter, if any
[1731156685] warming up the model with an empty run
[1731156696] 
[1731156696] system_info: n_threads = 8 / 4 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | 
[1731156696] add_bos: 1
[1731156696] tokenize the prompt
[1731156696] prompt: ""
[1731156696] tokens: [ '':1 ]
[1731156696] n_ctx: 2048
[1731156696] recalculate the cached logits (check): embd_inp.empty() false, n_matching_session_tokens 0, embd_inp.size() 1, session_tokens.size() 0, embd_inp.size() 1
[1731156696] inp_pfx: [ '':1, ' ':29871, '':13, '':13, '##':2277, '#':29937, ' Inst':2799, 'ruction':4080, ':':29901, '':13, '':13 ]
[1731156696] inp_sfx: [ ' ':29871, '':13, '':13, '##':2277, '#':29937, ' Response':13291, ':':29901, '':13, '':13 ]
[1731156696] main: interactive mode on.
[1731156696] Reverse prompt: '### Instruction:

'
[1731156696] Input prefix: '" "'
[1731156696] sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
[1731156696] generate: n_ctx = 2048, n_batch = 512, n_predict = -1, n_keep = 1
[1731156696] 

[1731156696] == Running in interactive mode. ==
[1731156696]  - Press Ctrl+C to interject at any time.
[1731156696]  - Press Return to return control to LLaMa.
 - To return control without starting a new line, end your input with '/'.
 - If you want to submit another line, end your input with '\'.

[1731156696] embd_inp.size(): 1, n_consumed: 0
[1731156696] eval: [ '':1 ]
[1731156708] n_past = 1
[1731156708] embd_inp.size(): 1, n_consumed: 1
[1731156708] waiting for user input
[1731156708] appending input prefix: '" "'
